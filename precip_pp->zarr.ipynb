{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline: `precipitation_flux` [.pp -> zarr]\n",
    "\n",
    "Using Iris and Xarray to consolidate `precipitation` data stored in many .pp files to one large Zarr store.\n",
    "\n",
    "This will follow the general pattern of:\n",
    "1. Load .pp for one time period  [Iris]\n",
    "2. Convert to zarr-able state  [Xarray]\n",
    "3. Append to Zarr store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Load sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/data/cssp-china/sample-data-17-01-20/cssp_china_pp'\n",
    "filename = 'apepda.pa508i0.pp'\n",
    "cubelist = iris.load(os.path.join(filepath, filename), 'precipitation_flux')\n",
    "cubelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube, = cubelist\n",
    "cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn this one cube into a Zarr store\n",
    "Onto which we can start appending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.lazy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cube is 2.5MB in size, which is a reasonable chunk size to have for our Zarr store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.DataArray.from_iris(cube)\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.chunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Xarray preserves the chunk size of the Iris cube\n",
    "\n",
    "Let's convert it to an xr.Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = da.to_dataset()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the np.ndarray to a dask.array\n",
    "ds1 = ds.chunk(chunks={'time':10, 'grid_latitude':219, 'grid_longitude':286})\n",
    "ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.precipitation_flux.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many chunks we be appending to the Zarray?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -1q {filepath} | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good number of chunks to try and append to the Zarr. At some point we might want to rechunk them (e.g. `100x100x100`) but for now let's not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `xr.Dataset` to Zarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.to_zarr('zarr_precip', consolidated=True, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if i==0:\n",
    "        ds1.to_zarr('zarr/2017f', consolidated=True, mode='w')\n",
    "    else:\n",
    "        ds1.to_zarr('zarr/2017f', consolidated=True, append_dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECIP_STASH = 'm01s05i216'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/data/cssp-china/sample-data-17-01-20/cssp_china_pp'\n",
    "filename = 'apepda.paj56i0.pp'\n",
    "# cube2, = iris.load(os.path.join(filepath, filename), iris.AttributeConstraint(STASH=PRECIP_STASH))\n",
    "cube2, = iris.load(os.path.join(filepath, filename), 'precipitation_flux')\n",
    "cube2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube2.data = cube2.core_data().rechunk((10,219,286))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube2.core_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = xr.DataArray.from_iris(cube2).to_dataset()\n",
    "ds2.precipitation_flux.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.to_zarr('zarr_precip', consolidated=True, append_dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z = xr.open_zarr('zarr_precip/')\n",
    "ds_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z.precipitation_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z.forecast_reference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "display([c for c in cube.coord('time').cells()])\n",
    "print()\n",
    "display([c for c in cube2.coord('time').cells()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filename)\n",
    "print('apepda.pa508i0.pp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir(filepath))[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.coord('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sorted(os.listdir(filepath))[0:4]:\n",
    "    cube, = iris.load(os.path.join(filepath, file), iris.AttributeConstraint(STASH=PRECIP_STASH))\n",
    "    \n",
    "    display([c for c in cube.coord('time').cells()])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datasci)",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
